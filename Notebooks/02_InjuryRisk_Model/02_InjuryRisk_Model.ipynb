{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09583223",
   "metadata": {},
   "source": [
    "# 02_InjuryRisk_Model.ipynb ‚Äî Injury Risk Prediction\n",
    "\n",
    "**Goal:** Build and evaluate predictive models for football player injury risk based on training, workload, and wellness data.\n",
    "\n",
    "**Objective:**\n",
    "- Create engineered features like ACWR, chronic load, fatigue indices.\n",
    "- Train multiple ML models (Logistic Regression, Random Forest, XGBoost).\n",
    "- Evaluate on predictive accuracy, interpret key risk drivers.\n",
    "- Export player-level injury risk predictions for Power BI visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Imports & setup ---\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, roc_curve, precision_recall_curve, average_precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import joblib, json, warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "plt.rcParams.update({'figure.figsize': (8,5), 'axes.grid': True})\n",
    "\n",
    "BASE = Path('.').resolve()\n",
    "DATA_IN = (BASE / '..' / 'data').resolve()\n",
    "OUT_MODELS = (BASE / '..' / 'models').resolve()\n",
    "OUT_REPORTS = (BASE / '..' / 'reports').resolve()\n",
    "OUT_MODELS.mkdir(parents=True, exist_ok=True)\n",
    "OUT_REPORTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('DATA_IN:', DATA_IN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33c3ce3",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e566f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_csv(DATA_IN / 'player_summary_for_model.csv')\n",
    "train = pd.read_csv(DATA_IN / 'train_features_prepared.csv', parse_dates=['Date'])\n",
    "\n",
    "print('Summary shape:', summary.shape)\n",
    "print('Train shape:', train.shape)\n",
    "summary.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f383d8",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b535f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine training and summary to derive engineered features\n",
    "df = train.merge(summary[['PlayerID','Position','Age','InjuryProneScore']], on='PlayerID', how='left')\n",
    "\n",
    "# Sort and create lag/rolling features\n",
    "df = df.sort_values(['PlayerID','Date']).reset_index(drop=True)\n",
    "df['Load'] = df['DistanceKM'] + 0.5*(df['DurationMinutes']/60.0)\n",
    "\n",
    "df['Acute7'] = df.groupby('PlayerID')['Load'].rolling(7, min_periods=1).sum().reset_index(0,drop=True)\n",
    "df['Chronic28'] = df.groupby('PlayerID')['Load'].rolling(28, min_periods=7).sum().reset_index(0,drop=True)\n",
    "df['ACWR'] = df['Acute7'] / df['Chronic28'].replace({0:np.nan})\n",
    "\n",
    "df['AvgHR_Roll7'] = df.groupby('PlayerID')['AvgHeartRate'].rolling(7, min_periods=3).mean().reset_index(0,drop=True)\n",
    "df['RPE_Roll7'] = df.groupby('PlayerID')['RPE'].rolling(7, min_periods=3).mean().reset_index(0,drop=True)\n",
    "df['Fatigue_Roll7'] = df.groupby('PlayerID')['FatigueLevel'].rolling(7, min_periods=3).mean().reset_index(0,drop=True)\n",
    "\n",
    "# Fill forward & clean NaNs\n",
    "df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56f26c1",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Define Injury Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate injury occurrence (1=injured in next 7 days)\n",
    "df['TargetInjury'] = 0\n",
    "for pid in df['PlayerID'].unique():\n",
    "    sub = df[df['PlayerID']==pid].copy()\n",
    "    inj_days = sub[sub['FatigueLevel']>8].index  # proxy rule for demonstration\n",
    "    future_idx = [i+3 for i in inj_days if i+3 < len(df)]\n",
    "    df.loc[future_idx, 'TargetInjury'] = 1\n",
    "\n",
    "target_rate = df['TargetInjury'].mean()\n",
    "print(f'Target injury rate: {target_rate:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225a731a",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Train/Test Split & Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce1d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['Load','ACWR','AvgHR_Roll7','RPE_Roll7','Fatigue_Roll7','Age','InjuryProneScore']\n",
    "X = df[feature_cols].copy()\n",
    "y = df['TargetInjury']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=feature_cols)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=feature_cols)\n",
    "\n",
    "print('Train size:', X_train.shape, 'Test size:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcbf6df",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4549d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, class_weight='balanced', random_state=RANDOM_STATE),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, class_weight='balanced'),\n",
    "    'XGBoost': XGBClassifier(n_estimators=200, max_depth=5, learning_rate=0.05, subsample=0.8, random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:,1]\n",
    "    roc = roc_auc_score(y_test, y_pred_proba)\n",
    "    ap = average_precision_score(y_test, y_pred_proba)\n",
    "    results[name] = {'ROC_AUC': roc, 'PR_AUC': ap}\n",
    "    print(f\"{name}: ROC_AUC={roc:.3f}, PR_AUC={ap:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dd1916",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Model Evaluation & Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b9969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = max(results.keys(), key=lambda k: results[k]['ROC_AUC'])\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print('Best model:', best_model_name, '‚Üí', results[best_model_name])\n",
    "\n",
    "y_pred_proba = best_model.predict_proba(X_test_scaled)[:,1]\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.title(f'Confusion Matrix ‚Äî {best_model_name}'); plt.xlabel('Predicted'); plt.ylabel('Actual')\n",
    "plt.colorbar(); plt.show()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.plot(fpr, tpr, label=f'{best_model_name} (AUC={roc_auc_score(y_test,y_pred_proba):.2f})')\n",
    "plt.plot([0,1],[0,1],'--',color='gray')\n",
    "plt.title('ROC Curve'); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f75f73",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3473e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = None\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importances = pd.Series(best_model.feature_importances_, index=feature_cols).sort_values(ascending=False)\n",
    "    plt.barh(importances.index, importances.values)\n",
    "    plt.title(f'Feature Importance ‚Äî {best_model_name}')\n",
    "    plt.gca().invert_yaxis(); plt.show()\n",
    "else:\n",
    "    print('No feature_importances_ attribute available.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf94b8ba",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Predict Injury Risk & Export Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f93c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PredictedRisk'] = best_model.predict_proba(scaler.transform(df[feature_cols]))[:,1]\n",
    "df['RiskCategory'] = pd.cut(df['PredictedRisk'], bins=[0,0.3,0.6,1.0], labels=['Low','Medium','High'])\n",
    "\n",
    "risk_today = df.groupby('PlayerID')[['PredictedRisk']].last().reset_index()\n",
    "risk_today = risk_today.merge(summary[['PlayerID','Position','Age']], on='PlayerID', how='left')\n",
    "\n",
    "out_path = OUT_REPORTS / 'InjuryRiskScores.csv'\n",
    "risk_today.to_csv(out_path, index=False)\n",
    "print('Saved injury risk scores to:', out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9ef46f",
   "metadata": {},
   "source": [
    "## üîü Save Model & Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22abb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = OUT_MODELS / f'{best_model_name}_injury_model.joblib'\n",
    "joblib.dump(best_model, model_path)\n",
    "joblib.dump(scaler, OUT_MODELS / 'scaler_injury.joblib')\n",
    "\n",
    "summary_report = {\n",
    "    'Model': best_model_name,\n",
    "    'ROC_AUC': results[best_model_name]['ROC_AUC'],\n",
    "    'PR_AUC': results[best_model_name]['PR_AUC'],\n",
    "    'FeatureCount': len(feature_cols),\n",
    "    'TargetRate': float(y.mean())\n",
    "}\n",
    "\n",
    "with open(OUT_REPORTS / 'injury_model_summary.json','w') as f:\n",
    "    json.dump(summary_report, f, indent=2)\n",
    "\n",
    "print('Saved model + summary.')\n",
    "summary_report\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
